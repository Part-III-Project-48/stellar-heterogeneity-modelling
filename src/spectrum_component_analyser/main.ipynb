{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a916007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482b3249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from astropy.visualization import quantity_support\n",
    "from astropy.units import Quantity\n",
    "quantity_support()\n",
    "from tqdm import tqdm\n",
    "import astropy.units as u\n",
    "import os\n",
    "\n",
    "from spectrum_component_analyser.internals.spectrum import spectrum\n",
    "from spectrum_component_analyser.internals.readers import read_JWST_fits,read_JWST_fits_all_spectra\n",
    "from spectrum_component_analyser.internals.spectral_grid import spectral_grid\n",
    "from spectrum_component_analyser.minimisation import calc_fitted_spectrum, get_optimality, plot_nicely, get_main_components\n",
    "\n",
    "star_name : str = \"LTT 3780\"\n",
    "star_temperature : Quantity[u.K] = 3350 * u.K\n",
    "\n",
    "__file__ = os.getcwd()\n",
    "jwst_file_segment_001 = (__file__ / Path(\"../../observed_spectra/MAST_2025-10-26T11_57_04.058Z - LTT-3780/MAST_2025-10-26T11_57_04.058Z/JWST/jw03557004001_04101_00001-seg001_nis_x1dints.fits\")).resolve()\n",
    "jwst_file_segment_002 = (__file__ / Path(\"../../observed_spectra/MAST_2025-10-26T11_57_04.058Z - LTT-3780/MAST_2025-10-26T11_57_04.058Z/JWST/jw03557004001_04101_00001-seg002_nis_x1dints.fits\")).resolve()\n",
    "jwst_file_segment_003 = (__file__ / Path(\"../../observed_spectra/MAST_2025-10-26T11_57_04.058Z - LTT-3780/MAST_2025-10-26T11_57_04.058Z/JWST/jw03557004001_04101_00001-seg003_nis_x1dints.fits\")).resolve()\n",
    "jwst_file_segment_004 = (__file__ / Path(\"../../observed_spectra/MAST_2025-10-26T11_57_04.058Z - LTT-3780/MAST_2025-10-26T11_57_04.058Z/JWST/jw03557004001_04101_00001-seg004_nis_x1dints.fits\")).resolve()\n",
    "\n",
    "spectrum_to_decompose : spectrum = read_JWST_fits(jwst_file_segment_001, INTEGRATION_INDEX=100, name=star_name, T_eff = star_temperature)\n",
    "\n",
    "mask = np.isfinite(spectrum_to_decompose.Fluxes) # & (spectrum_to_decompose.Wavelengths < 1.8 * u.um)\n",
    "\n",
    "spectrum_to_decompose = spectrum_to_decompose[mask]\n",
    "\n",
    "spectrum_to_decompose.plot()\n",
    "\n",
    "print(\"[SPECTRUM COMPONENT ANALYSER] : reading in hdf5\")\n",
    "# spectral_grid_relative_path = Path(\"../../spectral_grids/JWST_convolved_spectral_grid.hdf5\")\n",
    "spectral_grid_relative_path = Path(\"../../spectral_grids/JWST_convolved_not_oversmoothed.hdf5\")\n",
    "spectral_grid_absolute_path = (__file__ / spectral_grid_relative_path).resolve()\n",
    "spec_grid : spectral_grid = spectral_grid.from_hdf5(absolute_path=spectral_grid_absolute_path)\n",
    "print(\"[SPECTRUM COMPONENT ANALYSER] : finished reading in hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a541342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets analyse the JWST fits file: lets make a transmission curve\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "from spectrum_component_analyser.internals.readers import JWST_NORMALISING_POINT\n",
    "\n",
    "all_segments = [jwst_file_segment_001, jwst_file_segment_002, jwst_file_segment_003, jwst_file_segment_004]\n",
    "\n",
    "all_spectra = []\n",
    "\n",
    "for segment in all_segments:\n",
    "    all_spectra.extend(read_JWST_fits_all_spectra(segment, T_eff = None, name=star_name))\n",
    "\n",
    "total_fluxes = []\n",
    "for spec in all_spectra:\n",
    "    # this looks to remove quite a lot of information\n",
    "    spec.Wavelengths = spec.Wavelengths[mask]\n",
    "    spec.Fluxes = medfilt(spec.Fluxes[mask], kernel_size=3) * spec.Fluxes.unit\n",
    "    total_fluxes.append(np.sum(spec.Fluxes).value)\n",
    "\n",
    "    # less harsh option\n",
    "    # total_fluxes.append(np.sum(spec.Fluxes[mask]).value)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot([i for i in range(len(total_fluxes))], total_fluxes)\n",
    "plt.xlabel(\"Integration Index\")\n",
    "plt.ylabel(\"Total Flux / arbitrary units\")\n",
    "plt.title(\"Transit Light Curve for\" + star_name)\n",
    "plt.show()\n",
    "\n",
    "min_included_integration_index = 0\n",
    "max_included_integration_index = 300\n",
    "\n",
    "all_fluxes=[spec.Fluxes for spec in all_spectra[min_included_integration_index:max_included_integration_index]]\n",
    "\n",
    "spectrum_to_decompose = spectrum(wavelengths=all_spectra[0].Wavelengths,\n",
    "                                 fluxes=np.mean(all_fluxes, axis=0) * all_fluxes[0].unit,\n",
    "                                 normalised_point=JWST_NORMALISING_POINT,\n",
    "                                 temperature = star_temperature,\n",
    "                                 observational_resolution=None,\n",
    "                                 observational_wavelengths=None,\n",
    "                                 name=\"averaged\" + star_name)\n",
    "\n",
    "# spectrum_to_decompose = spectrum_to_decompose[mask]\n",
    "\n",
    "spectrum_to_decompose.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a296bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parameters = list(product(spec_grid.T_effs, [0, 1] * u.dimensionless_unscaled, [4.5, 5] * u.dimensionless_unscaled))\n",
    "# all_parameters = list(product(spec_grid.T_effs, [0 * u.dimensionless_unscaled], spec_grid.Log_gs))\n",
    "# all_parameters = list(product(spec_grid.T_effs, spec_grid.FeHs, [5 * u.dimensionless_unscaled]))\n",
    "# all_parameters = list(product(spec_grid.T_effs, spec_grid.FeHs, spec_grid.Log_gs))\n",
    "\n",
    "total_number_of_components = len(all_parameters)\n",
    "\n",
    "A, result = calc_fitted_spectrum(all_parameters,\n",
    "                                 spec_grid=spec_grid,\n",
    "                                 spectrum_to_decompose=spectrum_to_decompose,\n",
    "                                 mask=mask,\n",
    "                                 total_number_of_components=total_number_of_components,\n",
    "                                 max_iterations=1000)\n",
    "\n",
    "print(f\"residual MSE, residual sum of squares = {get_optimality(A, result, spectrum_to_decompose)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ee238",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from spectrum_component_analyser.minimisation import FEH_COLUMN, LOGG_COLUMN, TEFF_COLUMN, WEIGHT_COLUMN\n",
    "\n",
    "hash_map = plot_nicely(A, result, all_parameters, spec_grid, spectrum_to_decompose, star_name)\n",
    "\n",
    "weights = hash_map[WEIGHT_COLUMN].values\n",
    "\n",
    "teff_avg = np.average(hash_map[TEFF_COLUMN], weights=weights)\n",
    "feh_avg  = np.average(hash_map[FEH_COLUMN],  weights=weights)\n",
    "logg_avg = np.average(hash_map[LOGG_COLUMN], weights=weights)\n",
    "\n",
    "print(f\"T_eff avg = {teff_avg}\")\n",
    "print(f\"FeH avg = {feh_avg}\")\n",
    "print(f\"log g avg = {logg_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ec139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets re-run that, but with only the top few components and see if the fit is better\n",
    "\n",
    "# prolly want a new class for this\n",
    "# or could be a list of phoenix spectra; maybe that would help the above code be a bit neater too\n",
    "\n",
    "ns = np.arange(1, 20, 1)\n",
    "optimalities = np.array([])\n",
    "\n",
    "for number_of_components_to_keep in tqdm(ns):\n",
    "    \n",
    "    main_components = get_main_components(hash_map, number_of_components_to_keep)\n",
    "\n",
    "    A_restricted, result_restricted = calc_fitted_spectrum(main_components,\n",
    "                                                  spectrum_to_decompose=spectrum_to_decompose,\n",
    "                                                  spec_grid = spec_grid,\n",
    "                                                  mask=mask,\n",
    "                                                  total_number_of_components=len(main_components),\n",
    "                                                  verbose=False)\n",
    "\n",
    "    optimalities = np.append(optimalities, get_optimality(A_restricted, result_restricted, spectrum_to_decompose)[0])\n",
    "\n",
    "    # _ = plot_nicely(A_restricted, result_restricted, main_components, spec_grid, spectrum_to_decompose)\n",
    "\n",
    "# plt.clf()\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.semilogy(ns, optimalities)\n",
    "plt.semilogy(ns, [get_optimality(A, result, spectrum_to_decompose)[0]] * len(ns), linestyle=\"dashed\", label=\"optimality when using all PHOENIX spectra\")\n",
    "plt.xticks(ns)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"number of components considered\")\n",
    "plt.ylabel(\"Residual Mean Squared Error\")  #of matrix minimisation method (lower is more optimal)\n",
    "plt.title(f\"Optimality vs Number of Components Used\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b50bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now carry out an effectively identical analysis to calibration.py : input some known phoenix spectra, and shift their wavelengths back and forth until the spectra line up. see if this significantly improves things\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from astropy import units as u\n",
    "from astropy.visualization import quantity_support\n",
    "from astropy.modeling import models\n",
    "import scipy as sp\n",
    "\n",
    "from spectrum_component_analyser.minimisation import calc_fitted_spectrum_from_spectral_list\n",
    "\n",
    "quantity_support()\n",
    "\n",
    "from spectrum_component_analyser.internals.phoenix_spectrum import phoenix_spectrum\n",
    "from spectrum_component_analyser.internals.readers import JWST_NORMALISING_POINT, JWST_RESOLUTION\n",
    "from spectrum_component_analyser.internals.spectral_grid import download_spectrum, get_wavelength_grid\n",
    "from spectrum_component_analyser.internals.spectral_list import spectral_list\n",
    "from spectrum_component_analyser.internals.spectral_component import spectral_component\n",
    "\n",
    "number_of_components_to_keep = 5\n",
    "\n",
    "main_components : list[spectral_component] = get_main_components(hash_map, number_of_components_to_keep)\n",
    "\n",
    "\n",
    "max_roll_delta = 2\n",
    "roll_resolution = .0005 * u.um\n",
    "\n",
    "rolls = [i for i in reversed(range(-max_roll_delta, max_roll_delta))]\n",
    "\n",
    "def get_MSE(\n",
    "        shift : float, # in u.um (this isn't a quantity because scipy minimise prolly will complain)\n",
    "        plot : bool = False\n",
    "        ):\n",
    "    shift *= u.um\n",
    "    spec_list : spectral_list = spectral_list.from_internet(\n",
    "        spectral_components=main_components,\n",
    "        normalising_point=JWST_NORMALISING_POINT,\n",
    "        observational_resolution=JWST_RESOLUTION,\n",
    "        observational_wavelengths=spectrum_to_decompose.Wavelengths + shift,\n",
    "        name=\"small spectral grid\"\n",
    "    )\n",
    "\n",
    "    # can plot phoenix spectra for debugging\n",
    "    # s : phoenix_spectrum\n",
    "    # for s in spec_list.PhoenixSpectra:\n",
    "    #     s.plot(clear=False, show=False)\n",
    "    #     bb = models.BlackBody(temperature=s.T_eff)\n",
    "    #     plt.plot(s.Wavelengths, (bb(s.Wavelengths) * 4 * np.pi * u.sr).to(s.Fluxes.unit) / (models.BlackBody(temperature=3500 *u.K)(JWST_NORMALISING_POINT) * 4 * np.pi * u.sr ).to(s.Fluxes.unit).value, linestyle='dashed')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    A, result = calc_fitted_spectrum_from_spectral_list(\n",
    "        spec_list=spec_list,\n",
    "        mask=mask,\n",
    "        spectrum_to_decompose=spectrum_to_decompose,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # taken from minimisation.py's plot_nicely\n",
    "    if (plot):\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n",
    "\n",
    "        # --- First subplot: spectrum comparison ---\n",
    "        ax1.set_title(star_name)\n",
    "\n",
    "        determined_spectrum = spectrum(\n",
    "            spectrum_to_decompose.Wavelengths,\n",
    "            A @ result.x,\n",
    "            normalised_point=None, # carry out no normalisation or resampling on the determined spectrum (as this spectrum is a sum of spectra from PHOENIX which should already be formatted in this way)\n",
    "            observational_resolution=None,\n",
    "            observational_wavelengths=None,\n",
    "            temperature=None\n",
    "        )\n",
    "\n",
    "        ax1.plot(\n",
    "            spectrum_to_decompose.Wavelengths,\n",
    "            spectrum_to_decompose.Fluxes,\n",
    "            label=\"Observational JWST spectrum\"\n",
    "        )\n",
    "        ax1.plot(\n",
    "            determined_spectrum.Wavelengths,\n",
    "            determined_spectrum.Fluxes,\n",
    "            label=\"Fitted Spectrum\"\n",
    "        )\n",
    "\n",
    "        ax1.legend()\n",
    "\n",
    "        # --- Second subplot: residuals ---\n",
    "        residual = (determined_spectrum.Fluxes - spectrum_to_decompose.Fluxes) / spectrum_to_decompose.Fluxes\n",
    "\n",
    "        ax2.plot(spectrum_to_decompose.Wavelengths, residual)\n",
    "        ax2.set_ylabel(r\"Residual = $\\frac{\\mathrm{Fitted\\ Flux}-\\mathrm{Observed\\ Flux}}{\\mathrm{Observed\\ Flux}}$\")\n",
    "        ax2.set_xlabel(\"Wavelength / $\\mu$m\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    MSE, _ = get_optimality(A, result, spectrum_to_decompose)\n",
    "\n",
    "    print(f\"roll of {shift} gave MSE = {MSE}\")\n",
    "    return MSE\n",
    "\n",
    "# for roll_step in rolls:\n",
    "#     MSE = get_MSE(roll_step)\n",
    "#     print(f\"MSE = {MSE} : shift of {roll_step * roll_resolution}\")\n",
    "\n",
    "# sp.optimize.minimize(get_MSE, [0.0], bounds=[(-.01, .01)]) # gave me -0.0003748 * u.um\n",
    "\n",
    "# %matplotlib widget\n",
    "shifted_MSE = get_MSE(-0.0003656, plot = True) # shift is tiny if it does exist (~ resolution / 3)\n",
    "print(shifted_MSE)\n",
    "\n",
    "# original_MSE = get_MSE(-0., plot = True)\n",
    "# print(original_MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4cad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wavelength grid and example observational spectrum, test for rolls (this is a more crude approach than the one one or two code blocks above)\n",
    "\n",
    "phoenix_wavelengths = get_wavelength_grid()\n",
    "\n",
    "# nearby as in: nearby in parameter space to the observed spectrum\n",
    "nearby_phoenix_spectrum : phoenix_spectrum = download_spectrum(\n",
    "    3400 * u.K,\n",
    "    0.0,\n",
    "    5.0,\n",
    "    lte=True,\n",
    "    alphaM=0,\n",
    "    phoenix_wavelengths=phoenix_wavelengths,\n",
    "    normalising_point= JWST_NORMALISING_POINT,\n",
    "    observational_resolution= JWST_RESOLUTION,\n",
    "    observational_wavelengths = None,\n",
    "    name=\"nearby phoenix spectrum\"\n",
    ")\n",
    "\n",
    "mask = np.isfinite(spectrum_to_decompose.Fluxes)\n",
    "\n",
    "roll_resolution = 0.00001 * u.um\n",
    "\n",
    "def get_MSE(roll : int = 0) -> float:\n",
    "    # roll to find minimum\n",
    "    placed_onto_fluxes = np.interp(spectrum_to_decompose.Wavelengths, nearby_phoenix_spectrum.Wavelengths + roll * roll_resolution, nearby_phoenix_spectrum.Fluxes) # new y = np.interp(new x | old x | old y)\n",
    "\n",
    "    # mask _after_ rolling & interpolating\n",
    "    # the jwst data always seems to have some NaN; let's remove them\n",
    "    placed_onto_fluxes = placed_onto_fluxes[mask]\n",
    "\n",
    "    residual = (placed_onto_fluxes - spectrum_to_decompose[mask].Fluxes) / spectrum_to_decompose[mask].Fluxes\n",
    "    residual_mean_squared_error = np.sqrt(np.mean(residual**2))\n",
    "\n",
    "    return residual_mean_squared_error\n",
    "\n",
    "# how far to move the jwst spectrum to either side to check\n",
    "max_roll_delta : int = 1000\n",
    "\n",
    "MSEs = []\n",
    "rolls = [i for i in reversed(range(-max_roll_delta, max_roll_delta))]\n",
    "\n",
    "for i in rolls:\n",
    "    MSEs.append(get_MSE(i))\n",
    "\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.plot(rolls * roll_resolution, MSEs)\n",
    "plt.show()\n",
    "\n",
    "# looks to be 0.0042 um off - but fits from main.ipynb suggest moore like 0.0010 (just from eyeing it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spots-and-faculae-model-YvvEmflj-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
