{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a916007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482b3249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now, just request a random composite spectrum from facula_and_spot_creator\n",
    "# and try to decompose it - aka can we regenerate the w's\n",
    "\n",
    "# eventually can read in external data or some training data from a large hdf5 file etc\n",
    "\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from astropy.visualization import quantity_support\n",
    "quantity_support()\n",
    "from tqdm import tqdm\n",
    "import astropy.units as u\n",
    "import os\n",
    "\n",
    "from spectrum_component_analyser.internals.spectrum import spectrum\n",
    "from spectrum_component_analyser.internals.readers import read_JWST_fits,read_JWST_fits_all_spectra\n",
    "from spectrum_component_analyser.internals.spectral_grid import spectral_grid\n",
    "from spectrum_component_analyser.helper import calc_fitted_spectrum, get_optimality, plot_nicely, get_main_components\n",
    "\n",
    "script_dir = os.getcwd()\n",
    "\n",
    "jwst_file_segment_001 = (script_dir / Path(\"../../observed_spectra/MAST_2025-10-26T11_57_04.058Z - LTT-3780/MAST_2025-10-26T11_57_04.058Z/JWST/jw03557004001_04101_00001-seg001_nis_x1dints.fits\")).resolve()\n",
    "jwst_file_segment_002 = (script_dir / Path(\"../../observed_spectra/MAST_2025-10-26T11_57_04.058Z - LTT-3780/MAST_2025-10-26T11_57_04.058Z/JWST/jw03557004001_04101_00001-seg002_nis_x1dints.fits\")).resolve()\n",
    "jwst_file_segment_003 = (script_dir / Path(\"../../observed_spectra/MAST_2025-10-26T11_57_04.058Z - LTT-3780/MAST_2025-10-26T11_57_04.058Z/JWST/jw03557004001_04101_00001-seg003_nis_x1dints.fits\")).resolve()\n",
    "jwst_file_segment_004 = (script_dir / Path(\"../../observed_spectra/MAST_2025-10-26T11_57_04.058Z - LTT-3780/MAST_2025-10-26T11_57_04.058Z/JWST/jw03557004001_04101_00001-seg004_nis_x1dints.fits\")).resolve()\n",
    "\n",
    "spectrum_to_decompose : spectrum = read_JWST_fits(jwst_file_segment_001, INTEGRATION_INDEX=100, name=\"LTT 3780\")\n",
    "\n",
    "mask = np.isfinite(spectrum_to_decompose.Fluxes) & (spectrum_to_decompose.Wavelengths < 2.00 * u.um)\n",
    "\n",
    "spectrum_to_decompose = spectrum_to_decompose[mask]\n",
    "\n",
    "spectrum_to_decompose.plot()\n",
    "\n",
    "print(\"[SPECTRUM COMPONENT ANALYSER] : reading in hdf5\")\n",
    "# spectral_grid_relative_path = Path(\"../../spectral_grids/JWST_convolved_spectral_grid.hdf5\")\n",
    "spectral_grid_relative_path = Path(\"../../spectral_grids/JWST_convolved_not_oversmoothed.hdf5\")\n",
    "spectral_grid_absolute_path = (script_dir / spectral_grid_relative_path).resolve()\n",
    "spec_grid : spectral_grid = spectral_grid.from_hdf5(absolute_path=spectral_grid_absolute_path)\n",
    "lookup_table = spec_grid.to_lookup_table()\n",
    "print(\"[SPECTRUM COMPONENT ANALYSER] : finished reading in hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a541342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets analyse the JWST fits file: lets make a transmission curve\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "from spectrum_component_analyser.internals.readers import JWST_normalising_point\n",
    "\n",
    "all_segments = [jwst_file_segment_001, jwst_file_segment_002, jwst_file_segment_003, jwst_file_segment_004]\n",
    "\n",
    "all_spectra = []\n",
    "\n",
    "for segment in all_segments:\n",
    "    all_spectra.extend(read_JWST_fits_all_spectra(segment, name=\"LTT 3780\"))\n",
    "\n",
    "total_fluxes = []\n",
    "for spec in all_spectra:\n",
    "    # this looks to remove quite a lot of information\n",
    "    spec.Wavelengths = spec.Wavelengths[mask]\n",
    "    spec.Fluxes = medfilt(spec.Fluxes[mask], kernel_size=3) * spec.Fluxes.unit\n",
    "    total_fluxes.append(np.sum(spec.Fluxes).value)\n",
    "\n",
    "    # less harsh option\n",
    "    # total_fluxes.append(np.sum(spec.Fluxes[mask]).value)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot([i for i in range(len(total_fluxes))], total_fluxes)\n",
    "plt.xlabel(\"Integration Index\")\n",
    "plt.ylabel(\"Total Flux / arbitrary units\")\n",
    "plt.title(\"Transit Light Curve for LTT 3780\")\n",
    "plt.show()\n",
    "\n",
    "min_included_integration_index = 0\n",
    "max_included_integration_index = 250\n",
    "\n",
    "all_fluxes=[spec.Fluxes for spec in all_spectra[min_included_integration_index:max_included_integration_index]]\n",
    "\n",
    "spectrum_to_decompose = spectrum(wavelengths=all_spectra[0].Wavelengths,\n",
    "                                 fluxes=np.mean(all_fluxes, axis=0) * all_fluxes[0].unit,\n",
    "                                 normalised_point=JWST_normalising_point,\n",
    "                                 observational_resolution=None,\n",
    "                                 observational_wavelengths=None,\n",
    "                                 name=\"averaged LTT 3780\")\n",
    "\n",
    "# spectrum_to_decompose = spectrum_to_decompose[mask]\n",
    "\n",
    "spectrum_to_decompose.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a296bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parameters = list(product(spec_grid.T_effs, [0 * u.dimensionless_unscaled], [5 * u.dimensionless_unscaled]))\n",
    "# all_parameters = list(product(spec_grid.T_effs, spec_grid.FeHs, [5 * u.dimensionless_unscaled]))\n",
    "# all_parameters = list(product(spec_grid.T_effs, spec_grid.FeHs, spec_grid.Log_gs))\n",
    "\n",
    "total_number_of_components = len(all_parameters)\n",
    "\n",
    "A, result = calc_fitted_spectrum(all_parameters,\n",
    "                                 lookup_table,\n",
    "                                 spec_grid=spec_grid,\n",
    "                                 spectrum_to_decompose=spectrum_to_decompose,\n",
    "                                 mask=mask,\n",
    "                                 total_number_of_components=total_number_of_components,\n",
    "                                 max_iterations=1000)\n",
    "print(f\"residual MSE = {get_optimality(A, result, spectrum_to_decompose)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ee238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectrum_component_analyser.helper import FEH_COLUMN, LOGG_COLUMN, TEFF_COLUMN, WEIGHT_COLUMN\n",
    "\n",
    "hash_map = plot_nicely(A, result, all_parameters, spec_grid, spectrum_to_decompose)\n",
    "\n",
    "weights = hash_map[WEIGHT_COLUMN].values\n",
    "\n",
    "teff_avg = np.average(hash_map[TEFF_COLUMN], weights=weights)\n",
    "feh_avg  = np.average(hash_map[FEH_COLUMN],  weights=weights)\n",
    "logg_avg = np.average(hash_map[LOGG_COLUMN], weights=weights)\n",
    "\n",
    "print(teff_avg)\n",
    "print(feh_avg)\n",
    "print(logg_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ec139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets re-run that, but with only the top few components and see if the fit is better\n",
    "\n",
    "# prolly want a new class for this\n",
    "# or could be a list of phoenix spectra; maybe that would help the above code be a bit neater too\n",
    "\n",
    "ns = np.arange(1, 20, 1)\n",
    "optimalities = np.array([])\n",
    "\n",
    "for number_of_components_to_keep in tqdm(ns):\n",
    "    \n",
    "    main_components = get_main_components(hash_map, number_of_components_to_keep)\n",
    "\n",
    "    A_restricted, result_restricted = calc_fitted_spectrum(main_components,\n",
    "                                                  lookup_table,\n",
    "                                                  spectrum_to_decompose=spectrum_to_decompose,\n",
    "                                                  spec_grid = spec_grid,\n",
    "                                                  mask=mask,\n",
    "                                                  total_number_of_components=len(main_components),\n",
    "                                                  verbose=False)\n",
    "\n",
    "    optimalities = np.append(optimalities, get_optimality(A_restricted, result_restricted, spectrum_to_decompose)[0])\n",
    "\n",
    "    # _ = plot_nicely(A_restricted, result_restricted, main_components, spec_grid, spectrum_to_decompose)\n",
    "\n",
    "# plt.clf()\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.semilogy(ns, optimalities)\n",
    "plt.semilogy(ns, [get_optimality(A, result, spectrum_to_decompose)[0]] * len(ns), linestyle=\"dashed\", label=\"optimality when using all PHOENIX spectra\")\n",
    "plt.xticks(ns)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"number of components considered\")\n",
    "plt.ylabel(\"Residual Mean Squared Error\")  #of matrix minimisation method (lower is more optimal)\n",
    "plt.title(f\"Optimality vs Number of Components Used\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac576cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_components = get_main_components(hash_map, 7)\n",
    "\n",
    "shifted_lookup_table = {k: v.copy() for k, v in lookup_table.items()}\n",
    "\n",
    "for key, flux in shifted_lookup_table.items():\n",
    "    flux[:] = np.roll(flux, 0) # need the [:] for in place modification i.e. to change the reference\n",
    "\n",
    "A_restricted, result_restricted = calc_fitted_spectrum(main_components,\n",
    "                                              shifted_lookup_table,\n",
    "                                              spectrum_to_decompose=spectrum_to_decompose,\n",
    "                                              spec_grid=spec_grid,\n",
    "                                              mask=mask,\n",
    "                                              total_number_of_components=len(main_components),\n",
    "                                              verbose=False)\n",
    "\n",
    "print(f\"Residual MSE = {get_optimality(A_restricted, result_restricted, spectrum_to_decompose)[0]}\")\n",
    "\n",
    "_ = plot_nicely(A_restricted, result_restricted, main_components, spec_grid, spectrum_to_decompose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5358b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can try another meta-optimiser: shift the spectrum between [-20,+20] or smthn resolutions to the left & right\n",
    "# there might be some small zero error on the phoenix grid or smthn (I wouldn't be suprised) - this would help check for that\n",
    "\n",
    "# from experimenting: no rolling is best\n",
    "main_comps = get_main_components(hash_map, 10)\n",
    "\n",
    "optimalities = []\n",
    "\n",
    "# independent copy - we dont want the shift to affect the original lookup_table\n",
    "shifted_lookup_table = {k: v.copy() for k, v in lookup_table.items()}\n",
    "\n",
    "shifts = np.arange(-10,10,1)\n",
    "\n",
    "for key, flux in shifted_lookup_table.items():\n",
    "    flux[:] = np.roll(flux, np.min(shifts)) # need the [:] for in place modification i.e. to change the reference\n",
    "\n",
    "A, result = calc_fitted_spectrum(main_comps,\n",
    "                        shifted_lookup_table,\n",
    "                        spectrum_to_decompose=spectrum_to_decompose,\n",
    "                        spec_grid=spec_grid,\n",
    "                        mask=mask,\n",
    "                        total_number_of_components=len(main_comps),\n",
    "                        verbose=False)\n",
    "\n",
    "optimalities.append(get_optimality(A, result, spectrum_to_decompose)[0])\n",
    "\n",
    "positive_shifts = shifts + np.abs(np.min(shifts))\n",
    "\n",
    "for shift in tqdm(positive_shifts[0:-1]):\n",
    "    for key, flux in shifted_lookup_table.items():\n",
    "        flux[:] = np.roll(flux, 1) # need the [:] for in place modification i.e. to change the reference\n",
    "    A, result = calc_fitted_spectrum(main_comps,\n",
    "                            shifted_lookup_table,\n",
    "                            spectrum_to_decompose=spectrum_to_decompose,\n",
    "                            spec_grid=spec_grid,\n",
    "                            mask=mask,\n",
    "                            total_number_of_components=len(main_comps),\n",
    "                            verbose=False)\n",
    "    optimalities.append(get_optimality(A, result, spectrum_to_decompose)[0])\n",
    "\n",
    "    # plot_nicely(A, result, main_comps)\n",
    "\n",
    "plt.clf()\n",
    "plt.semilogy(shifts, optimalities)\n",
    "plt.xlabel(\"roll / shift\")\n",
    "plt.ylabel(\"optimality of solution (using top 10 best components only)\")\n",
    "plt.show()\n",
    "\n",
    "# now we can fit in sections too\n",
    "\n",
    "# can also interpolate in different ways\n",
    "\n",
    "# also can visualise other spectra; see what works\n",
    "\n",
    "# also can use other spectra from lalitha"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spots-and-faculae-model-YvvEmflj-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
