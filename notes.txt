okay so we need a model that trains on

combined spectra (pseudo-random) + weights of each component

and when given any graph gives the closest representation of that graph as a sum of the components, aka gives us the weights
and from those weights we can tell the fractional area of each temperature

[DONE] normalisation
[DONE] basic ML of some sort
[DONE] make a spectrum class that has all the things we need like normalisation etc

add proof that the temperature interpolation is working to documentation.md

---

add the full hdf5 file to a google drive (run on main pc to create)

[DONE] maybe convert fits_to_hdf5 to use astropy quantities... might be nice (kinda needed lmao)

## notes: may as well remove out of range/bounds wavelengths before appending to df, even if we're not regularising the grid
        
stream data to hdf5? to make it a little less bad?

[DONE] can update wavelength regularisation to include gaussian convolution?

we could test our model on the suns spectra as then maybe the % of area at different temperatures to T_eff might be known...

idrk how the experimental data should be used? should i average over all the integration data? or just use the 1st one? etc

also idrk about the smoothing im doing on the phoenix data to get it into JWST resolution, e.g. at ~2um it looks very smooth, much smoother than down below 1um

THE question rn is : does PHOENIX library actually contain all the necessary data? i.e. is the residuals of my plots in main.ipynb from exoplanet stuff? or is there spikes that would appear at 0.1 FeH resolution etc that we're missing that we simply cannot optimise for with the current PHOENIX data?
If we are SURE that a good optimisation of PHOENIX components HAS to span all the spectra needed for just stellar spectra, then the discepencies are expected (from exoplanet etc???)

the numerically fitted spectrum looks to be like 2 indices shifted to the right compared to the experimental spectrum?

maybe see if you can fit just 1 component to the spectra, and see how much worse/better that is than a sum of x components
-> if its more or less just as good, then our model might not be doing anything that fancy atm

[DONE] way better way of doing spectral grid would be a class
contains a dataframe with 4 columns
first 3 columns are the paramters
but the 4th column is a reference to a spectrum object
way better than this astropy stuff i think

reorganise codebase - e.g. make all notes in one place, simplify github issues; make the poetry package top level; refactor spectral grid to contain objects

plot fitting in different sections
[DONE] parallelise the new code plz lmao

[DONE] creating the hdf5 file is massively untested with the new spectrum_grid

work out why the gaussian medfilt looks as if its flattening out the higher wavelength range of JWST
maybe it isnt - is the PHOENIX data just actually flatter there?
if so, then maybe that area is just very noisy in the JWST spectra

create some code to analyse the JWST spectra over different integration indices i.e. to see the transit graph (of total flux vs integration_index for all 4 (or however many) files)
and maybe to see the 

[FIXED] i dont believe the optimizeresult.optimality is a good number: bad looking fits can have very small optimality; e.g. rolling an axis by like 5000 still seems to fit well

could use the matrix minimisation method to find
1) number of components to fit for
2) initial guess for their weights

also it would maybe be better to be testing the matrix min method on multiple stars at once (as some stars might simply not have sun spots, we don't rly know lmao)

could also add alphaM in, why not, the code is plently fast enough so it would just be 1 slightly slow download

maybe re-add in temperature interpolation into fits_to_hdf5 file?
idk if temperature interpolation would help the matrix minimisation or ML minimisation though... (ig it wouldn't, but idrk ofc)

could link code to JWST api so that users can just request a given star straight from the JWST database (this is probably something for later)

np.roll(+-1) etc doesnt seem to help on JWST spectra - but maybe a slight shift in freq before convolution would help?
the spectral lines are quite narrow, so things could be quite sensitive to a small change in wavelength
what you could do to test this: componentise a spectrum to find its e.g. top 10 components, then make a temporary spectral grid using just those 10 components at a higher resolution. now shift by tiny amounts of wavelength and then convolve, get fit optimality, and plot. maybe there is some small shift out.

or just use higher res spectra lmao

or use a different minimiser like Harris suggested

looks like the medfilt is smoothing out the phoenix spectra far too much for the HARPS wavelengths, maybe wanna check that somehow

[DONE] we should be saving to spectral_grids data that is convolved to a given resolution (to save space)
[DONE] then normalising it when we read it in?

- fitting in sections
- take an average of the a section of the integration indices (e.g. indices 0 - 100) - these will be manually chosen by just plotting the tranmission curve and choosing a section that does not look to include the exoplanet's atmosphere
- also maybe use some scipy code to remove outliers?











---

workout how unnormalized the resulting spectrum is when constraining metallacity and log_g
workout how to constrain sum of w_i's = 1 (if necessary)

this right/left shift between the data maybe wants debugging (and then remaking a new spectral grid)


test other star data: when constraining the parameters to nearby the true parameters (and then temperature +- 500K or whatever) is the graph always underrepresenting the red region?
if yes, then something about our approach might be off
if no, then those stars which are underrepped in the red might just have spots near the edges that are being _limb darkened_

kinda crazy idea but why not plot the fitting variables over time? like average over 5 adjacent spectra and produce 50 data points. if they're all randomly around then its prolly wrong




[DONE} do meta calibration
compare to current teff feh logg (interpolated) beliefs
if its better than ours, then something is up with the code
if its worse, then either their analysis assuming 1 component is invalid (and maybe it would be worth trying to prove that multi component stars fail to be approximated well by 1 component), or the PHOENIX-ACES (or whatever model they are using) disagrees with the PHOENIX model spectra we are using, or there's some interpolation error etc (or maybe the spectrum we're creating from the JWST data is just wrong)

maybe have a look to see how minimisation is being done by the LTT 3780 papers